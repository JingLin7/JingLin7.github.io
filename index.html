<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>Jing Lin 林靖</title>
    <link href="./css/style.css" rel="stylesheet" media="all" type="text/css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"
    />
    <script
      type="text/javascript"
      src="https://code.jquery.com/jquery-2.2.0.min.js"
    ></script>

    <script
      src="https://kit.fontawesome.com/57fb8d417e.js"
      crossorigin="anonymous"
    ></script>

    <script type="text/javascript">
      window.onload = choosePic;
      var myPix = new Array("./about/jinglin.jpeg");
      function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
      }
      function lastUpdate() {
        var x = document.lastModified.substr(0, 10);
        document.getElementById("demo").innerHTML = x;
      }
    </script>
    <script type="text/javascript" src="./js/hidebib.js"></script>
    <script type="text/javascript" src="./js/loadtxt.js"></script>
  </head>

  <body onload="lastUpdate()">
    <div class="content">
      <div id="container">
        <table>
          <tbody>
            <tr>
              <td>
                <img
                  id="myPicture"
                  src="./about/jinglin.jpeg"
                  style="
                    float: left;
                    margin-top: 30px;
                    margin-left: 30px;
                    border-radius: 10%;
                  "
                  width="180px"
                />
              </td>
              <td>
                <div id="DocInfo">
                  <div id="intro">
                    <h1>Jing Lin 林靖</h1>
                    <!-- <a target='_blank'
                        href='https://goo.gl/maps/vfTQ6Gbbg3gNvzTZ8'
                        title='Location'>
                        <font size="5"><i class='fas
                            fa-map-marker-alt'></i></font>
                      </a> -->
                    <a
                      style="color: black"
                      href="https://www.tsinghua.edu.cn/"
                      >Tsinghua University</a
                    ><br />
                    <br />
                    <a href="mailto: jinglin.stu@gmail.com">
                      <span
                        class="fa fa-envelope"
                        style="color: navy; font-size: 20px"
                      >
                        <span style="font-family: Optima Bold"
                          >jinglin.stu</span
                        >
                        <span
                          class="fa fa-at"
                          style="color: navy; font-size: 20px"
                          ><span style="font-family: Optima Bold">
                            gmail.com</span
                          ></span
                        ></span
                      ></a
                    >
                    <br />
                  </div>
                  <br />
                  <ul class="icon-list">
                    <a style="color: black" href="./about/jinglin.pdf">
                      <span class="ai ai-cv fa-xl"></span>
                    </a>

                    <a
                      style="color: black"
                      href="https://scholar.google.com.hk/citations?user=SvaU2GMAAAAJ&hl=zh-CN"
                    >
                      <span class="ai ai-google-scholar fa-xl"></span>
                    </a>

                    <a
                      style="color: black"
                      href="https://github.com/linjing7"
                    >
                      <span class="fa-brands fa-github fa-xl"></span>
                    </a>

                    <!-- <a
                      style="color: black"
                      href="https://www.researchgate.net/profile/Yuliang-Xiu"
                    >
                      <span class="ai ai-researchgate fa-xl"></span>
                    </a> -->
                    <span style="color: gray; font-weight: normal">|</span>
                    <!-- <a
                      style="color: black"
                      href="https://www.linkedin.com/in/yuliangxiu"
                    >
                      <span class="fa fa-linkedin fa-xl"></span>
                    </a> -->


                    <!-- <a
                      style="color: black"
                      href="https://www.facebook.com/xiuyuliang1993"
                    >
                      <span class="fa fa-facebook fa-xl"></span>
                    </a> -->

                    <a
                      style="color: black"
                      href="https://www.zhihu.com/people/jinglin7"
                    >
                      <span class="fa-brands fa-zhihu fa-xl"></span>
                    </a>

                    <a
                      style="color: black"
                      href="https://www.youtube.com/channel/UCjBkdQZhlgfjDSdDDLYSvMg"
                    >
                      <span class="fa-brands fa-youtube fa-xl"></span>
                    </a>

                    <!-- <a
                      style="color: black"
                      href="https://space.bilibili.com/86857008"
                    >
                      <span class="fa-brands fa-bilibili fa-xl"></span>
                    </a> -->

                  </ul>

                  <br />
                </div>
                <br />
              </td>
            </tr>
          </tbody>
        </table>
        <table>
          <tr>
            <td>
              <br />
              <h1>Biography</h1>

              I am currently a 2nd-Year Master student in 
              <a href="https://www.sigs.tsinghua.edu.cn/">Shenzhen International Graduate School</a>,
              <strong
                >Tsinghua University</strong
              >, under the supervision of
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=eldgnIYAAAAJ&view_op=list_works&sortby=pubdate"
                >Haoqian Wang</a
              >. Currently, my research topic is
              <i
                >Image/video-based 3D human motion perception and generation</i
              >. Previously, I focused on low-level vision, e.g., image/video restoration, computational imaging.
              <!-- which is part of the
              <a href="https://www.clipe-itn.eu/">CLIPE</a> initiative and
              funded by the European Union’s Horizon 2020 Research and
              Innovation Programme.  -->
              <br /><br />
              I got B.Eng. degree in Automation at <a href="https://www.hitsz.edu.cn/index.html"
              >Harbin Institute of Technology (Shenzhen)</a
            >. 
              I worked as a research intern at <a href="https://shunsukesaito.github.io/">Huawei</a>
              (Noah's Ark Lab)
              <strong></strong>
              with 
              <a href="https://xueyizou.github.io/">Xueyi Zou</a>, and <a href="https://shunsukesaito.github.io/">IDEA</a> under the supervision of 
              <a href="https://ailingzeng.site">Ailing Zeng</a> and <a href="https://www.leizhang.org/">Lei Zhang</a>.

              <br/><br />
              I'm passionate about open-source code. Codes, models, and datasets of my works are released and have earned over 1.3K stars. 
              Check out <a href="https://github.com/linjing7">my GitHub page</a>! I am an activate player in competitions of international top academic conferences and 
              I have won the champion on <a href="https://codalab.lisn.upsaclay.fr/competitions/721">NTIRE Spectral Recovery Challenge</a> at CVPR2022, 
              Third Place on <a href="https://competitions.codalab.org/competitions/28051">NTIRE Video Super-Resolution Challenge</a> at CVPR 2021.
              Our OSX ranks top-1 on <a href="https://agora-evaluation.is.tuebingen.mpg.de/">AGORA</a> benchark from Nov. 2022 to Apr. 2023.
              
              <br /><br />
              In the future, I hope to continue the research on computer vision and computer graphics (CV & CG), 
              particularly in relation to <strong>3d human motion</strong>, including motion perception (e.g., motion capture, pose estimation), 
              generation (e.g., text/audio-driven motion generation), and understanding (e.g., human-object interaction). 

              <br /><br />
              <strong style="color: red"
                >I am looking for a PHD position in
                Fall, 2024 (<a href="about/jinglin.pdf">CV</a>,
                <a href="mailto: jinglin.stu@gmail.com">Email</a>). Please contact me if there are available positions in your lab. 
                <!-- I'm open to any meaningful and interesting topics during PHD. -->
              </strong>

            </td>
          </tr>
        </table>

        <!-- <a href="https://www.youtube.com/channel/UCicL0Co86tGbzoV2heWiEaA"
          ><img
            src="https://img.shields.io/youtube/channel/views/UCicL0Co86tGbzoV2heWiEaA?logo=youtube&labelColor=ce4630&style=flat-plastic"
        /></a> -->
        <br /><br />

        <!-- <h1>News</h1>
        [2023/01-06] Invited
        <a
          href="https://www.bilibili.com/video/BV1NM4y1B7UN/?spm_id_from=333.999.list.card_archive.click&vd_source=4fa43a1b25f1451c4212f214517d8932"
          ><i class="fa fa-video" aria-hidden="true">&nbsp;</i>Talk&nbsp;(30
          min)</a
        >
        <em>"Towards Large-scale Human Digitization: Implicit or Explicit?"</em>
        (<a
          href="https://www.dropbox.com/s/7ncqw60nkr8g7ud/ECON%26ICON.pdf?dl=0"
          >slides</a
        >, 75MB) at <strong>industry</strong> (Taichi, Shanghai AI Lab, BIGAI,
        Huawei) and <strong>academia</strong> (PKU, CUHK, UCLA, ETH Zurich, SDU,
        CAS). <br />
        [2023/04/23] ECON won
        <strong style="color: brown">Outstanding Poster (4/80)</strong> in China
        3DV. <br />
        [2023/04/16] Now both
        <a
          href="https://huggingface.co/spaces/Yuliang/ECON"
          style="padding-left: 0.5rem; vertical-align: top"
          ><img
            src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-ECON-orange"
        /></a>
        and
        <a
          href="https://colab.research.google.com/drive/1YRgwoRCZIrSB2e7auEWFyG10Xzjbrbno?usp=sharing"
          style="padding-left: 0.5rem; vertical-align: top"
          ><img
            src="https://colab.research.google.com/assets/colab-badge.svg"
            alt="Google Colab"
        /></a>
        are available for ECON users!<br />
        [2023/03/21] ECON has been selected as
        <strong style="color: brown">CVPR highlight</strong> papers (10% of
        accepted papers, 2.5% of submissions). <br />
        [2023/03/15] 💕
        <strong
          >I'm thrilled to announce that Cathy and I are finally tying the knot!
          💍
        </strong>
        <a style="color: brown" href="./about/love.jpeg"
          ><strong>Love Moment</strong></a
        ><br />
        [2023/02/27] <a href="https://xiuyuliang.cn/econ">ECON</a> and
        <a href="https://tingtingliao.github.io/CAR/">CAR</a> got accepted by
        <strong style="color: brown">CVPR 2023</strong>
        <iframe
          src="https://ghbtns.com/github-btn.html?user=yuliangxiu&repo=ECON&type=star&count=true&v=2&size=small"
          frameborder="0"
          scrolling="0"
          width="100"
          height="20"
        ></iframe
        ><br />
        [2023/02/13]
        <a
          href="https://www.nytimes.com/interactive/2023/02/13/sports/football/kadarius-toney-punt-return-super-bowl-chiefs.html"
          ><em
            ><strong style="color: brown">NYTimes</strong>"See How Kansas City
            Secured Its Comeback"</em
          ></a
        >, ICON for Super Bowl 2023!<br />
        [2023/01/12] Multiple contributors support
        <a
          href="https://github.com/YuliangXiu/ECON/blob/master/docs/installation-windows.md"
          >Windows</a
        >,
        <a
          href="https://github.com/YuliangXiu/ECON/blob/master/docs/installation-docker.md"
          >Docker</a
        >,
        <a href="https://carlosedubarreto.gumroad.com/l/CEB_ECON">Blender</a>
        and<a
          href="https://colab.research.google.com/drive/1YRgwoRCZIrSB2e7auEWFyG10Xzjbrbno?usp=sharing"
          style="padding-left: 0.5rem"
          >Google Colab</a
        >
        for ECON, bravo!<br />
        [2022/12/20]
        <a
          href="https://rd.nytimes.com/projects/modeling-key-world-cup-moments-with-machine-learning"
          ><em
            ><strong style="color: brown">NYTimes</strong>"Modeling Key World
            Cup Moments with Machine Learning"</em
          ></a
        >, ICON for World Cup 2022!<br />
        <a href="javascript:toggleblock(&#39;old_news&#39;)"
          >---- show more ----</a
        >
        <div id="old_news" style="display: none">
          [2022/12/15] <a href="https://icon.is.tue.mpg.de/">ICON</a> belongs to
          the past, <a href="https://xiuyuliang.cn/econ">ECON</a> is the
          future!<br />
          [2022/11/07]
          <a href="https://arxiv.org/abs/2211.03375">AlphaPose</a> finally got
          accepted by <strong style="color: brown">TPAMI 2022</strong>
          <iframe
            src="https://ghbtns.com/github-btn.html?user=MVIG-SJTU&repo=AlphaPose&type=star&count=true&v=2&size=small"
            frameborder="0"
            scrolling="0"
            width="200"
            height="20"
          ></iframe
          ><br />
          [2022/09/17] <a href="https://dart2022.github.io/">DART</a> got
          accepted by <strong style="color: brown">NeurIPS 2022</strong>
          <i style="color: brown">- Datasets and Benchmarks Track</i>.
          <iframe
            src="https://ghbtns.com/github-btn.html?user=DART2022&repo=DART&type=star&count=true&v=2&size=small"
            frameborder="0"
            scrolling="0"
            width="100"
            height="20"
          ></iframe
          ><br />
          [2022/08/29] I am invited to give a talk at <b>Adobe's</b> Digital
          Human Seminar.<br />
          [2022/08/01]
          <a
            href="https://huggingface.co/spaces/Yuliang/ICON"
            style="padding-left: 0.5rem"
            ><img
              src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-ICON-orange"
          /></a>
          <a
            href="https://colab.research.google.com/drive/1-AWeWhPvCTBX0KfMtgtMk10uPU05ihoA?usp=sharing"
            style="padding-left: 0.5rem"
            ><img
              src="https://colab.research.google.com/assets/colab-badge.svg"
              alt="Google Colab"
          /></a>
          of ICON, play with it on your images!<br />

          [2022/04/20] Invited to talk about
          <a href="https://www.buzzsprout.com/1914034/10466744">ICON</a> at
          Talking Papers Podcast. Great chat with
          <a href="https://www.itzikbs.com/">Yizhak Ben-Shabat</a>!<br />
          [2022/04/07] 走进马克思普朗克智能系统研究所与苏黎世联邦理工AIT团队
          <a
            href="https://app6ca5octe2206.pc.xiaoe-tech.com/page/1827300?navIndex=3"
            ><i class="fa fa-video" aria-hidden="true">&nbsp;</i
            >视频(中文)&nbsp;</a
          >[<a href="https://jmq.xet.tech/s/8he6q">上</a>,
          <a href="https://jmq.xet.tech/s/ld2pb">下</a>]. <br />
          [2022/03/02] <a href="https://icon.is.tue.mpg.de/">ICON</a> got
          accepted by <strong style="color: brown">CVPR 2022</strong> &#8594;
          <a href="https://readpaper.com/paper/4569785684533977089"
            ><i class="fas fa-comments" aria-hidden="true">&nbsp;</i
            >Reader&nbsp;</a
          ><a href="https://discord.gg/Vqa7KBGRyk"
            ><i class="fab fa-discord" aria-hidden="true">&nbsp;</i
            >Discord&nbsp;</a
          ><br />
          [2022/02/01] I am invited to give Tech Talks by <b>USC-ICT</b>, and
          <b>Meta Reality Labs, Pittsburgh</b> (<a
            href="https://www.dropbox.com/s/bymd8zryce6cckf/ICON-ICT%26Meta.pdf?dl=0"
            >PDF</a
          >, 21MB).<br />
          [2021/12/17] New work "ICON: Implicit Clothed humans Obtained from
          Normals", please check its
          <a href="https://icon.is.tue.mpg.de/">page</a>.<br />
          [2020/09/01] Get admitted to
          <a href="http://clipe-itn.eu/">CLIPE ESR11</a> and will be joining
          <a href="https://ps.is.mpg.de/person/black">Michael Black</a>'s team
          at MPI for Intelligent Systems.<br />
          [2020/08/26]
          <a href="https://youtu.be/THxYxcEnKFk"
            >" Volumetric Human Teleportation"</a
          >
          won <strong style="color: orangered">Best in Show Award </strong>of
          SIGGRAPH Real-Time Live 2020!<br />
          [2020/08/25]
          <a href="https://project-splinter.github.io/">Project-Splinter</a>:
          Human Digitization with Implicit Representation is launched!<br />
          [2020/07/02] Our "Monoport: Monocular Real-Time Volumetric
          Teleportation" work was accepted by
          <strong style="color: brown">ECCV 2020</strong>
          <br />
          [2020/05/08] Our "Volumetric Human Teleportation" demo was accepted by
          <strong style="color: brown">SIGGRAPH Real-Time Live 2020</strong>
          <br />
          [2019/03/03] I will be joining USC CS Ph.D. Program in fall 2019,
          advised by Hao Li <br />
          [2019/01/24] I gave an invited
          <a
            href="https://ps.is.tuebingen.mpg.de/talks/pose-trajectory-extraction-and-novel-view-synthesis-from-visual-content"
            >talk</a
          >
          at MPI for Intelligent Systems, Perceiving Systems department.
          <br />
        </div>
        <br /><br /> -->

        <h1 id="citation">Publications</h1>

        <!-- Favorite papers are
        <span style="background-color: lightgoldenrodyellow">highlighted</span>. -->

        <br />
        <table class="pub_table">
          <tr id="motion_x">
            <td class="pub_td1">
              <a href="https://motion-x-dataset.github.io/">
                <img src="./about/motion_x_resize.gif" />
              </a>            </td>
            <td class="pub_td2">
              <b
                >Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset
                &nbsp;</b
              >
              <a href="https://github.com/IDEA-Research/Motion-X">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/IDEA-Research/Motion-X?style=social">
              </a>
              <br /><br />
              <strong>Jing Lin*</strong>,
              <a href="https://ailingzeng.site">Ailing Zeng*</a>,
              <a href="https://shunlinlu.github.io/">Shunlin Lu*</a>,
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai</a>,
              <a href="http://www.zhangruimao.site/">Ruimao Zhang</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://www.leizhang.org/">Lei Zhang</a>
              
              <br />
              <i>
                Preprint, Under Review</i>
              <br /><br />
              <a href="https://motion-x-dataset.github.io/"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2304.03903">arXiv</a>,
              <a href="https://readpaper.com/paper/4743346846252941313"
                >Reader</a
              >]  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="osx">
            <td class="pub_td1">
              <a href="https://osx-ubody.github.io/">
                <img src="./about/osx_resize.gif" />
              </a>
            </td>
            <td class="pub_td2">
              <b
                >One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer
                &nbsp;</b
              >
              <a href="https://github.com/IDEA-Research/OSX">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/IDEA-Research/OSX?style=social">
              </a>
              <iframe
                frameborder="0"
                scrolling="0"
                width="100"
                height="20"
              ></iframe>
              <br /><br />
              <strong>Jing Lin</strong>,
              <a href="https://ailingzeng.site">Ailing Zeng</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://www.leizhang.org/">Lei Zhang</a>,
              <a href="https://yu-li.github.io/">Yu Li</a>
              
              <br />
              <i
                >Computer Vision and Pattern Recognition 2023 (<strong
                  style="color: brown"
                  >CVPR 2023</strong
                >)</i>
              <br /><br />
              <a href="https://osx-ubody.github.io/"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="http://arxiv.org/abs/2303.16160">arXiv</a>,
              <a href="https://readpaper.com/paper/1698361644206378752"
                >Reader</a
              >]
              <a href="https://www.youtube.com/watch?v=s0cG3OVXQUo&t=2s"
                ><i class="fa fa-video" aria-hidden="true">&nbsp;</i
                >Video&nbsp;</a
              >  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="fgst">
            <td class="pub_td1">
              <a href="https://github.com/linjing7/VR-Baseline">
                <img src="./about/fgst_resize.gif" />
              </a>            
            </td>
            <td class="pub_td2">
              <b
                >Flow-Guided Sparse Transformer for Video Deblurring
                &nbsp;</b
              >
              <a href="https://github.com/linjing7/VR-Baseline">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/linjing7/VR-Baseline?style=social">
              </a>
              <br /><br />
              <strong>Jing Lin*</strong>,
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai*</a>,
              <a href="https://scholar.google.com/citations?user=a_WRvyIAAAAJ&hl=zh-CN">Xiaowan Hu</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://scholar.google.com/citations?user=JPUwfAMAAAAJ&hl=zh-CN">Youliang Yan</a>,
              <a href="https://xueyizou.github.io/">Xueyi Zou</a>,
              <a href="https://henghuiding.github.io/">Henghui Ding</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://people.ee.ethz.ch/~timofter/">Radu Timofte</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              
              <br />
              <i
                >International Conference on Machine Learning 2022 (<strong
                  style="color: brown"
                  >ICML 2022</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/linjing7/VR-Baseline"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2201.01893">arXiv</a>,
              <a href="https://readpaper.com/paper/4577344522149699585"
                >Reader</a
              >]
  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="s2svr">
            <td class="pub_td1">
              <a href="https://github.com/linjing7/VR-Baseline">
                <img src="./about/s2svr_resize.gif" />
              </a>               
            </td>
            <td class="pub_td2">
              <b
                >Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video Restoration
                &nbsp;</b
              >
              <a href="https://github.com/linjing7/VR-Baseline">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/linjing7/VR-Baseline?style=social">
              </a>
              <br /><br />
              <strong>Jing Lin*</strong>,
              <a href="https://scholar.google.com/citations?user=a_WRvyIAAAAJ&hl=zh-CN">Xiaowan Hu*</a>,
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://scholar.google.com/citations?user=JPUwfAMAAAAJ&hl=zh-CN">Youliang Yan</a>,
              <a href="https://xueyizou.github.io/">Xueyi Zou</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              <br />
              <i
                >International Conference on Machine Learning 2022 (<strong
                  style="color: brown"
                  >ICML 2022</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/linjing7/VR-Baseline"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2205.10195">arXiv</a>,
              <a href="https://readpaper.com/paper/688616683445972992"
                >Reader</a
              >]
  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="mst">
            <td class="pub_td1">
              <a href="https://github.com/caiyuanhao1998/MST">
                <img src="./about/mst.png" />
              </a>             
            </td>
            <td class="pub_td2">
              <b
                >Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction
                &nbsp;</b
              >
              <a href="https://github.com/caiyuanhao1998/MST">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/caiyuanhao1998/MST?style=social">
              </a>
              <br /><br />
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai*</a>,
              <strong>Jing Lin*</strong>,
              <a href="https://scholar.google.com/citations?user=a_WRvyIAAAAJ&hl=zh-CN">Xiaowan Hu</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://xygroup6.github.io/xygroup/">Xin Yuan</a>,
              <a href="https://henghuiding.github.io/">Henghui Ding</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://people.ee.ethz.ch/~timofter/">Radu Timofte</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              <br />
              <i
                >Computer Vision and Pattern Recognition (<strong
                  style="color: brown"
                  >CVPR 2022</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/caiyuanhao1998/MST"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2111.07910">arXiv</a>,
              <a href="https://readpaper.com/paper/4558558423944273921"
                >Reader</a
              >]
  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="cst">
            <td class="pub_td1">
              <a href="https://github.com/caiyuanhao1998/MST">
                <img src="./about/cst_resize.gif" />
              </a>              
            </td>
            <td class="pub_td2">
              <b
                >Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction
                &nbsp;</b
              >
              <a href="https://github.com/caiyuanhao1998/MST">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/caiyuanhao1998/MST?style=social">
              </a>
              <br /><br />
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai*</a>,
              <strong>Jing Lin*</strong>,
              <a href="https://scholar.google.com/citations?user=a_WRvyIAAAAJ&hl=zh-CN">Xiaowan Hu</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://xygroup6.github.io/xygroup/">Xin Yuan</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://people.ee.ethz.ch/~timofter/">Radu Timofte</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              <br />
              <i
                >European Conference on Computer Vision 2022 (<strong
                  style="color: brown"
                  >ECCV 2022</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/caiyuanhao1998/MST"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2203.04845">arXiv</a>,
              <a href="https://readpaper.com/paper/661826470455304192"
                >Reader</a
              >]
  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="dauhst">
            <td class="pub_td1">
              <a href="https://github.com/caiyuanhao1998/MST">
                <img src="./about/dauhst.png" />
              </a>             
            </td>
            <td class="pub_td2">
              <b
                >Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging
                &nbsp;</b
              >
              <a href="https://github.com/caiyuanhao1998/MST">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/caiyuanhao1998/MST?style=social">
              </a>
              <br /><br />
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai*</a>,
              <strong>Jing Lin*</strong>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://xygroup6.github.io/xygroup/">Xin Yuan</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://people.ee.ethz.ch/~timofter/">Radu Timofte</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              <br />
              <i
                >Conference on Neural Information Processing Systems 2022 (<strong
                  style="color: brown"
                  >NeurIPS 2022</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/caiyuanhao1998/MST"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2205.10102">arXiv</a>,
              <a href="https://readpaper.com/paper/4626666723047653377"
                >Reader</a
              >]
        
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>

          <tr id="mst++">
            <td class="pub_td1">
              <a href="https://github.com/caiyuanhao1998/MST-plus-plus">
                <img src="./about/mst_pp_resize.gif" />
              </a>            
            </td>
            <td class="pub_td2">
              <b
                >MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral Reconstruction
                &nbsp;</b
              >
              <a href="https://github.com/caiyuanhao1998/MST-plus-plus">
                <img alt="GitHub stars" style="vertical-align: middle" src="https://img.shields.io/github/stars/caiyuanhao1998/MST-plus-plus?style=social">
              </a>
              <br /><br />
              <a href="https://caiyuanhao1998.github.io">Yuanhao Cai*</a>,
              <strong>Jing Lin*</strong>,
              <a href="https://caiyuanhao1998.github.io">Zudi Lin</a>,
              <a href="https://www.sigs.tsinghua.edu.cn/whq/">Haoqian Wang</a>,
              <a href="https://yulunzhang.com/">Yulun Zhang</a>,
              <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a>,
              <a href="https://people.ee.ethz.ch/~timofter/">Radu Timofte</a>,
              <a href="https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html">Luc Van Gool</a>
              <br />
              <i
                >Conference on Computer Vision and Pattern Recognition Workshops 2022 (<strong
                  style="color: brown"
                  >CVPRW 2022 Oral</strong
                >)</i>
              <br /><br />
              <a href="https://github.com/caiyuanhao1998/MST"
                ><i class="fas fa-home" aria-hidden="true">&nbsp;</i
                >Home&nbsp;</a
              >
              <a href=""
                ><i class="fa fa-file-lines" aria-hidden="true">&nbsp;</i></a
              >[<a href="https://arxiv.org/abs/2204.07908">arXiv</a>,
              <a href="https://readpaper.com/paper/4614357200290193409"
                >Reader</a
              >]
  
              <pre id="carbib" xml:space="preserve" style="display: none"></pre>
              <span id="carabs" style="display: none"></span>
            </td>
          </tr>
        </table>
        
        <h1>Honors & Awards</h1>
        <ul>
          <li>
            Winner of NTIRE Spectral Reconstruction Challenge at CVPR 2022
          </li>
          <li>
            Third Place of NTIRE Video Super-Resolution Challenge at CVPR 2021
          </li>
          <li>
            National Scholarship (2019)
          </li>
          <li>
            First Class Scholarship (2019, 2020, 2022)
          </li>
        </ul>

        <h1>Academic Service</h1>
        <ul>
          <li>
            <strong>Reviewers of</strong>: CVPR, ECCV, ICCV, NeurIPS, ICME
          </li>
        </ul>
        <div align="center">
          <div style="width: 200px; height: 300px">
            <script
              type="text/javascript"
              src="//rf.revolvermaps.com/0/0/6.js?i=5hhec4lz2y4&amp;m=1&amp;c=ff0000&amp;cr1=ffffff&amp;f=ubuntu&amp;l=0&amp;s=300&amp;bv=100&amp;hi=20"
              async="async"
            ></script>
          </div>
          <br />
          <!-- <strong -->
            This website is created with this <a href="https://xiuyuliang.cn/">template</a>,
            last updated at
            <span style="color: blue" id="demo"></span>.
          <br />
        </div>
        
      </div>
    </div>
  </body>
</html>
